{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMw+a7/wxzJTxM4C89PRoM1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grownsandip/ML_Algo/blob/main/Logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODAY WE WILL LEARN LOGISTIC REGRESSION USNG SCIKIT LEARN**"
      ],
      "metadata": {
        "id": "2ch17diBGPOh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR9qVLctF67K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**we will be using titanic dataset of sk learn for binary classification as it has only two options either person has lived or has died in the event, we will try to predic this , for that we will fetch openml from sklearn**"
      ],
      "metadata": {
        "id": "hFXfQ7M5HaUD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml"
      ],
      "metadata": {
        "id": "xg_lHHd_Hv5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_data=fetch_openml(\"titanic\",version=1,as_frame=True) #as_frame=True means we are converting into frame dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShRDKgPFILLT",
        "outputId": "05decafb-ea7e-4696-9490-0e4175b31647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=titanic_data['data']"
      ],
      "metadata": {
        "id": "2Wr9Vy6cI7DR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "storing target data inside titanic in a data frame"
      ],
      "metadata": {
        "id": "as1zTnc-JBTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['survived']=titanic_data['target']"
      ],
      "metadata": {
        "id": "t7-HH3ekJFzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "checking the features or attributes in the dataset"
      ],
      "metadata": {
        "id": "PJeBwyonJkG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Mw_-dAucJSSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "graphically showing how many survived and howmany died"
      ],
      "metadata": {
        "id": "q1yBrsWYKFIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='survived',data=df)"
      ],
      "metadata": {
        "id": "8M4o8FKeKLwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gender bases number of survivor"
      ],
      "metadata": {
        "id": "4HERA8c0KlqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='survived',hue='sex',data=df)"
      ],
      "metadata": {
        "id": "ZNqNhuemKpll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x='survived',hue='pclass',data=df)"
      ],
      "metadata": {
        "id": "lChlbzWeLH5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['age'].plot.hist()"
      ],
      "metadata": {
        "id": "rC16KWA9Ld23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "looking at the data types of our datasets"
      ],
      "metadata": {
        "id": "0VLcyxSkLtoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "8dQ5TyqkLyVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "looking at the nuul values we have in the data sets columnwise"
      ],
      "metadata": {
        "id": "_xeBEok5MIaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "MzNcEUgaMN-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will represnt missing values in percentage"
      ],
      "metadata": {
        "id": "4LQ1_9AAON36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_vals=pd.DataFrame(df.isnull().sum()/len(df)*100)\n",
        "missing_vals.plot(kind='bar',title='missing values in percentage',ylabel='percentage')"
      ],
      "metadata": {
        "id": "Dl5lc1o-OSn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are combining sibsp and parch column together to create family column giving it more meaning"
      ],
      "metadata": {
        "id": "oFE5JQn6P6uf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['family']=df['sibsp']+df['parch']\n",
        "df.loc[df['family']>0,'travelled alone']=0\n",
        "df.loc[df['family']==0,'travelled alone']=1"
      ],
      "metadata": {
        "id": "Jd5VjBzSQCSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['family'].head()\n"
      ],
      "metadata": {
        "id": "E_nkmbhXRP-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dropping the sibsp and parch columns"
      ],
      "metadata": {
        "id": "v7RMfiaPRvHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['sibsp','parch'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "6oBP6HYIRzgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dropping some unused features form the dataset that wont contribute in learning process"
      ],
      "metadata": {
        "id": "CYmyza4hTczc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['name','home.dest','ticket'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "2JPK8SBJTn34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "UQUqL7bET3zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['cabin','body','boat'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "m7dePCBbUUGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "zbCsD6p0UseC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we have to do value imputation basically meaning converting data values like \"male\",\"female\" to machine understandable values we can do that using get dummy values"
      ],
      "metadata": {
        "id": "AyO-9OYiU_Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sex=pd.get_dummies(df['sex'],drop_first=True)\n",
        "print(sex)"
      ],
      "metadata": {
        "id": "uqJJBBElVX7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "Zeb4Lk3zWgee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "as we can see there are still null values existing in the dataset so we can eradicate these using simple imputer of sklearn"
      ],
      "metadata": {
        "id": "G3rxSFAJWlUr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imp_mean=SimpleImputer(strategy='mean')"
      ],
      "metadata": {
        "id": "RBKk6qwwWyhO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now apply this imputer filter to the missing dataset columns"
      ],
      "metadata": {
        "id": "xHweTQN_Xdlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['age']=imp_mean.fit_transform(df[['age']])"
      ],
      "metadata": {
        "id": "09VLkK9MXkS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['fare']=imp_mean.fit_transform(df[['fare']])"
      ],
      "metadata": {
        "id": "-tsBdaY_X2N_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "VDzCsW-GYVgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for embarked column we have character data so we have to use most frequent strategy"
      ],
      "metadata": {
        "id": "8a6xKY9WYg9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imp_f=SimpleImputer(strategy='most_frequent')\n",
        "df['embarked']=imp_f.fit_transform(df[['embarked']])"
      ],
      "metadata": {
        "id": "obZXrCdbYpq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "W1lB0GgRbm6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embark=pd.get_dummies(df['embarked'],drop_first=True)\n",
        "print(embark)"
      ],
      "metadata": {
        "id": "PqhaIgCrdj6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will drop embarked column and add embark column to the data frame"
      ],
      "metadata": {
        "id": "eWveyOaAeday"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['embarked'],axis=1,inplace=True)\n",
        "df=pd.concat([df,embark],axis=1)"
      ],
      "metadata": {
        "id": "wTAbjLR1ejHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "seperating feature data and label data in the x and y parameter"
      ],
      "metadata": {
        "id": "NC4lywf0fkvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.drop(['survived'],axis=1)\n",
        "x.head()"
      ],
      "metadata": {
        "id": "kDsOWsyZfr8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df['survived']\n",
        "y.head()"
      ],
      "metadata": {
        "id": "Se_rNvxVgAEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we are seperating traing data and testing data and we are keeping the size of testing data as 30% of data"
      ],
      "metadata": {
        "id": "rULya6MUgftP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)"
      ],
      "metadata": {
        "id": "g9Ifnb9jgpAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape,y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uvgGg8GEh7rw",
        "outputId": "41e62cd7-c860-480f-cb1a-3e9b2a08c02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(916, 8) (916,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test.shape,y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA0B_jEWiCw2",
        "outputId": "373dc29f-81ab-43ad-c64c-aa20d882a877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(393, 8) (393,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we are going to import model and apply our data to that"
      ],
      "metadata": {
        "id": "_VPGL_KqiefM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model=LogisticRegression()\n",
        "model.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "75x-wVBYij08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prediction based on testing dataset"
      ],
      "metadata": {
        "id": "mGyIyCQYjYjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model.predict(x_test)"
      ],
      "metadata": {
        "id": "iTDYWkUdjb9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "for accuracy finding we get"
      ],
      "metadata": {
        "id": "GzamcTmNkTyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,pred)"
      ],
      "metadata": {
        "id": "2CI20oUskYOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can aslo check the confusion metrics for better understanding further"
      ],
      "metadata": {
        "id": "mnAmIxYukoGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(y_test,pred)"
      ],
      "metadata": {
        "id": "qX3oUr6wkvqO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}